# Conclusion

Machine learning (ML) is an exciting discipline that provides opportunities for new insights and breakthroughs. However, in order for businesses to be able to justify their investment in ML, it is important that they are able to extract as much value as possible from their machine learning applications. In order for this to happen, it is important for ML models to progress beyond the proof-of-concept (PoC) phase and into production. This is the most effective way for the models’ output to be integrated into a business’s operations. Further, post-deployment, these models must continue to generate value for as long as they are ‘in production’. Thus, it is really important that organizations’ implementation of machine learning can deliver and support this type of sustained value. That’s why COPML is such a useful framework for ML development – successful model development is the start, not the end of the ML lifecycle.

In this paper we have explored how COPML helps data science managers and their cross-functional teams make well-considered decisions about the tools, infrastructure and governance they need to build resilient and value-generating ML applications and systems. Getting these things right will also minimize the causes of friction in cross-team working by making it easier to collaborate effectively.

Selecting the right infrastructure enables an appropriate level of automation as well as a unified approach to security and governance. This increases the chance that your team(s) will be able to follow good practice without being overburdened by some of the more tedious requirements for achieving this. Wherever you are in your machine learning journey, COPML coupled with the Cloudera Data Platform can help you go further and deliver greater value.

1. Big Tech is used to collectively describe the most popular and best-performing American technology companies e.g. Facebook, Amazon, Microsoft, Apple, Netflix and Alphabet etc. ↑
2. In practice, a model being trained for real world use would probably be trained on a dataset comprising a wider set of x-ray images e.g. x-ray images of lungs infected by diseases other than pneumonia. ↑
3. This threshold will be determined by a number of factors such as the degree of variability in the underlying data, the volume of predictions made by the model relative to the number of examples it was trained on etc. ↑
4. There are other risks as well. For example, the paper, [_The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks_](https://arxiv.org/pdf/1802.08232.pdf) __ explores the risk of inadvertent memorization by neural network models. ↑
5. https://gdpr-text.com/read/article-22/ ↑
6. It is worth highlighting here that correlation isn’t causation, consequently, there are risks to building retention purely on the basis of correlation. Cloudera Fast Forward Lab’s [Causality for Machine Learning report ](https://ff13.fastforwardlabs.com)explores the application of causality in a machine learning context. ↑
